class(myData)  # "data.frame"
attributes(myData)
# Рассчитайте описательные статистики.
summary(myData)
# Рассчитайте винзорированную (триммированную) среднюю по каждой переменной и сопоставьте это значение с исходным средним
# медианным значением. Сделайте выводы.
winsor.mean(select_if(myData, is.numeric), trim = 0.2, na.rm = TRUE)
winsor.mean(select_if(myData, is.numeric), trim = 0.2, na.rm = TRUE)
library("psych")
library(zoo)
library(dplyr)
myData <- iris
#### 1.3 Проверьте, есть ли наблюдения, в которых значения по какому-либо параметру отсутствуют, и выведите список этих значений. ####
sum(is.na(myData)) # NA отсутствуют
myData[c(1, 3, 51), c(2, 4)] <- NA # заменим некоторые данные на NA
is.na(myData)
sum(is.na(myData)) # 6 NA
myDataNA <- myData # сохраним дата фрейм с пропусками, т.к. мы его использовать вместо исходного файла
myData[!complete.cases(myData),] # ропуски имеются на пересечении строк 1, 3 и 51 и столбцов Sepal.Width Petal, Petal.Width
# Примите решение, что, на ваш взгляд, целесообразно в данном случае сделать с пропущенными значениями.
# В частности, подставьте вместо отсутствующих значений среднее с помощью функции na.aggregate либо удалите значения с пропусками.
myData[] <- lapply(myData_NA, na.aggregate)
sum(is.na(myData)) # 0 NA
# Кратко ответьте на следующие вопросы.
#  1)	Что является элементарной единицей в этом наборе данных?
# Ответ: один цветок
#  2)	Определите вид данных: одномерные, двумерные, многомерные?
dim(myData)
# Ответ: двумерные данные.
#  3)	Определите какие из этих переменных количественные, а какие качественные?
str(myData)
# library(dplyr)
colnames(select_if(myData, is.numeric)) # "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"
colnames(select_if(myData, is.factor)) #  "Species"
# Ответ: "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"
#  4)	Какие из этих переменных номинальные? Какие порядковые?
# Ответ:
#  5)	Это временной ряд или данные об одном временном срезе?
# Ответ:
#  6)	Укажите, какие операции можно применять к каждой из переменных
# Ответ:
#  7)	Сформулируйте (в общих терминах), на какие вопросы можно найти ответы при детальном анализе набора данных такого типа.
# Ответ:
# Проверьте количество наблюдений и переменных.
dim(myData) # 150 наблюдений и 50 переменных
# Проверьте названия переменных.
names(myData) # "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
# Проверьте структуру данных. В частности, количественные переменные должны иметь атрибут «числовая»,
# качественные – «factor», а также являются ли данные таблицей или фреймом.
str(myData)
colnames(select_if(myData, is.numeric)) # количественные: "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"
colnames(select_if(myData, is.factor)) #  качественные: "Species"
typeof(myData) # "list"
class(myData)  # "data.frame"
attributes(myData)
# Рассчитайте описательные статистики.
summary(myData)
# Рассчитайте винзорированную (триммированную) среднюю по каждой переменной и сопоставьте это значение с исходным средним
# медианным значением. Сделайте выводы.
winsor.mean(select_if(myData, is.numeric), trim = 0.2, na.rm = TRUE)
modMed <- summary(myData)
rm(modMed)
modMed <- summary(myData)
modMed
modMed[c(median, means), -5]
modMed[c(median, mean), -5]
modMed[c(modMed$median, modMed$mean), -5]
modMed <- summary(myData)
modMed
rm(modMed)
aggregate(myDataNA, FUN = c(mean, median()))
mean(select_if(myData, is.numeric))
mean(select_if(myData, is.numeric)
means(select_if(myData, is.numeric)
means(select_if(myData, is.numeric))
mean(select_if(myData, is.numeric))
winsor.mean(select_if(myDataNA, is.numeric), trim = 0.2, na.rm = TRUE)
mean(select_if(myData, is.numeric))
mean(select_if(myData, is.numeric))
mean(myData$Sepal.Length)
mean(c(myData$Sepal.Length, myData$Sepal.Width, myData$Petal.Length, myData$Petal.Width)
mean(c(myData$Sepal.Length, myData$Sepal.Width, myData$Petal.Length, myData$Petal.Width))
mean(myData$Sepal.Length, myData$Sepal.Width, myData$Petal.Length, myData$Petal.Width)
myData
names(myData)
aggregate(cbind(Sepal.Length, Sepal.Width),  myData, sd)
aggregate(cbind('Sepal.Length', 'Sepal.Width'),  myData, sd)
aggregate(cbind('Sepal.Length', 'Sepal.Width'),  myData, mean)
describe(myData)
describe
describe(myDataNA)
describe(myDataNA)[-5, 3]
winsor.mean(select_if(myDataNA, is.numeric), trim = 0.2, na.rm = TRUE)
names(myData)
winsor.mean(select_if(myDataNA, is.numeric), trim = 0.2, na.rm = TRUE)
describe(myDataNA)
describe(myDataNA[, -5])
describe(myDataNA[, -5])['mean']
describe(myDataNA[, -5])['mean', 'sd']
describe(myDataNA[, -5])['mean', 'median']
describe(myDataNA[, -5])[c('mean', 'median')]
describe(myDataNA[, -5])[c('mean', 'median')]
winsor.mean(select_if(myDataNA, is.numeric), trim = 0.2, na.rm = TRUE)
as.data.frame(winsor.mean(select_if(myDataNA, is.numeric), trim = 0.2, na.rm = TRUE))
as.data.frame(winsor.mean(select_if(myData, is.numeric), trim = 0.2, na.rm = TRUE))
describe(myDataNA[, -5])[c('mean', 'median')]
# Проверьте данные на наличие выбросов по каждой переменной, присвоив ей буквенное значение (x1, х2, х3…).
x1 <- myData[, 1]
boxplot.stats(x1)$out
boxplot(x1)
# Значения, которые являются выбросами для всех переменных:
df <- data.frame(x1, х2, х3, х4)
x2 <- myData[, 2]
boxplot.stats(x2)$out
boxplot(x2)
x3 <- myData[, 3]
boxplot.stats(x3)$out
boxplot(x3)
x4 <- myData[, 4]
boxplot.stats(x4)$out
boxplot(x4)
boxplot(x3)
x4 <- myData[, 4]
boxplot.stats(x4)$out
boxplot(x4)
boxplot.stats(x3)$out
boxplot.stats(x4)$out
boxplot.stats(x2)$out
df <- data.frame(x1, х2, х3, х4)
x2 <- myData[, 2]
boxplot.stats(x2)$out
boxplot(x2)
# Значения, которые являются выбросами для всех переменных:
df <- data.frame(x1, х2, х3, х4)
# Значения, которые являются выбросами для всех переменных:
df <- data.frame(x1, x2, х3, х4)
# Значения, которые являются выбросами для всех переменных:
df <- data.frame(x1, x2, x3, x4)
df
rm(x1,х2,х3,х4)
attach(df)
(a <- which(x1 %in% boxplot.stats(x1)$out))
rm(x1,х2,х3,х4)
attach(df)
a <- which(x1 %in% boxplot.stats(x1)$out)
a <- which(x1 %in% boxplot.stats(x1)$out)
a
(a <- which(SEPALLEN%in% boxplot.stats(SEPALLEN)$out))
a <- which(SEPALLEN%in% boxplot.stats(SEPALLEN)$out)
df
df <- data.frame(x1, x2, x3, x4)
a <- which(x1 %in% boxplot.stats(x1)$out)
a
b <- which(х2 %in% boxplot.stats(х2)$out)
(b <- which(х2 %in% boxplot.stats(х2)$out))
(c<- ……….
(a <- which(x1 %in% boxplot.stats(x1)$out))
(b <- which(х2 %in% boxplot.stats(x2)$out))
(a <- which(x1 %in% boxplot.stats(x1)$out))
(b <- which(x2 %in% boxplot.stats(x2)$out))
boxplot.stats(x4)$out
boxplot.stats(x2)$out
(c<-  which(x3 %in% boxplot.stats(x3)$out))
(c <-  which(x3 %in% boxplot.stats(x3)$out))
(d <-  which(x4 %in% boxplot.stats(x4)$out))
d <-  which(x4 %in% boxplot.stats(x4)$out)
(d <-  which(x4 %in% boxplot.stats(x4)$out))
detach(df)
df
outlier.list1 <- intersect(х1,х2,х3,х4))
df
outlier.list1 <- intersect(х1,х2,х3,х4))
oulier_list1 <- Reduce(intersect, list(a,b,c,d))
oulier_list2 <- Reduce(union, list(a,b,c,d))
oulier_list1
oulier_list2
# Для выделения выбросов необходимо убрать, при ее наличии, качественную переменную, записав данные под новым именем:
myData2 <- myData[,1:4]
head(myData2)
kmeans.result <- kmeans(myData2, centers = 3)
# Проведите кластеризацию методом К-средних, выделив три кластера:
kmeans.result <- kmeans(myData2, centers = 3, na.rm = T)
# Проведите кластеризацию методом К-средних, выделив три кластера:
kmeans.result <- kmeans(myData2, centers = 3)
head(df)
View(myDataNA)
# Проведите кластеризацию методом К-средних, выделив три кластера:
kmeans.result <- kmeans(df, centers = 3)
df <- data.frame(x1, x2, x3, x4)
kmeans.result <- kmeans(df, centers = 3)
# Проведите кластеризацию методом К-средних, выделив три кластера:
is.na(df)
# Проведите кластеризацию методом К-средних, выделив три кластера:
sum(is.na(df))
# Проведите кластеризацию методом К-средних, выделив три кластера:
sum(is.na(myData))
myData[] <- lapply(myData_NA, na.aggregate)
sum(is.na(myData)) # 0 NA
myData[] <- lapply(myData_NA, na.aggregate)
myData[] <- lapply(myDataNA, na.aggregate)
sum(is.na(myData)) # 0 NA
x1 <- myData[, 1]
boxplot.stats(x1)$out
boxplot(x1)
x2 <- myData[, 2]
boxplot.stats(x2)$out
boxplot(x2)
x3 <- myData[, 3]
boxplot.stats(x3)$out
boxplot(x3)
x4 <- myData[, 4]
boxplot.stats(x4)$out
boxplot(x4)
# Значения, которые являются выбросами для всех переменных:
df <- data.frame(x1, x2, x3, x4)
rm(x1,х2,х3,х4)
rm(x1, x2, x3, x4)
# Проведите кластеризацию методом К-средних, выделив три кластера:
sum(is.na(myData))
kmeans.result <- kmeans(df, centers = 3)
kmeans.result
# Отобразите центры кластеров:
kmeans.result$centers
# Рассчитайте расстояния от объектов до центров кластеров:
centers <- kmeans.result$centers[kmeans.result$cluster, ]
distances <- sqrt(rowSums((myData2 - centers)^2))
centers
distances
distances <- sqrt(rowSums((myData - centers)^2))
distances
# Рассчитайте расстояния от объектов до центров кластеров:
centers <- kmeans.result$centers[kmeans.result$cluster, ]
distances <- sqrt(rowSums((myData - centers)^2))
myData <- myData[, 1:4]
# Проведите кластеризацию методом К-средних, выделив три кластера:
sum(is.na(myData))
kmeans.result <- kmeans(df, centers = 3)
kmeans.result
# Рассчитайте расстояния от объектов до центров кластеров:
centers <- kmeans.result$centers[kmeans.result$cluster, ]
centers
distances <- sqrt(rowSums((myData - centers)^2))
distances
# Возьмите несколько (например, 5) наибольших получившихся расстояний.
outliers <- order(distances, decreasing=T)[1:5]
outliers
print(outliers)
print(myData[outliers, ])
plot(iris2[,c("Sepal.Length", "Sepal.Width")], pch="o", col=kmeans.result$cluster, cex=0.3)
points(kmeans.result$centers[,c("Sepal.Length", "Sepal.Width")], col=1:3, pch=8, cex=1.5)
points(iris2[outliers, c("Sepal.Length", "Sepal.Width")], pch="+", col=4, cex=1.5)
plot(iris2[,c("Sepal.Length", "Sepal.Width")], pch="o", col=kmeans.result$cluster, cex=0.3)
plot(myData[,c("Sepal.Length", "Sepal.Width")], pch="o", col=kmeans.result$cluster, cex=0.3)
plot(myData[, c("Sepal.Length", "Sepal.Width")], pch ="o", col = kmeans.result$cluster, cex = 0.3)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 1.5)
points(myData[outliers, c("Sepal.Length", "Sepal.Width")], pch = "+", col = 4, cex = 1.5)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 1.5)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 1.5)
plot(myData[, c("Sepal.Length", "Sepal.Width")], pch ="o", col = kmeans.result$cluster, cex = 0.3)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 1.5)
points(myData[outliers, c("Sepal.Length", "Sepal.Width")], pch = "+", col = 4, cex = 1.5)
plot(myData[, c("Sepal.Length", "Sepal.Width")], pch ="o", col = kmeans.result$cluster, cex = 0.3)
print(myData[outliers, ])
print(myData[outliers, ])
plot(myData[, c("Sepal.Length", "Sepal.Width")], pch ="o", col = kmeans.result$cluster, cex = 0.3)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 1.5)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = 8, cex = 1.5)
kmeans.result$centers
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = '8', cex = 1.5)
points(kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")], col = 1:3, pch = "8", cex = 1.5)
kmeans.result$centers[, c("Sepal.Length", "Sepal.Width")]
plot(myData[, c("Sepal.Length", "Sepal.Width")], pch ="o", col = kmeans.result$cluster, cex = 0.3)
points(kmeans.result$centers[, c("x1", "x2")], col = 1:3, pch = 8, cex = 1.5)
points(myData[outliers, c("Sepal.Length", "Sepal.Width")], pch = "+", col = 4, cex = 1.5)
print(myData[outliers, ])
# Кратко опишите, какие наблюдения являются аномальными:
# Ответ:
names(myData[outliers, ])
# Кратко опишите, какие наблюдения являются аномальными:
# Ответ:
rownames(myData[outliers, ])
oulier_list1
oulier_list2
# Кратко опишите, какие наблюдения являются аномальными:
# Ответ:
rownames(myData[outliers, ]) # "99",  "58", "94", "61", "119"
oulier_list1 <- Reduce(intersect, list(a,b,c,d))
oulier_list1
oulier_list2
oulier_list2
outliers <- order(distances, decreasing=T)[1:5]
outliers
sqrt(rowSums((myData - centers)^2))
setwd("C:/Users/GudievZK/Desktop/GitHub/DF/)
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
### Задание 1. ###
# Имеется фрагмент базы данных об анкетировании клиентов турфирмы. Разделите данные на обучающую и тестовую выборки по 70% и 30%,
# либо используя другие проценты по своему усмотрению.
# library(party)
set.seed(1234)
ind <- sample(2, nrow(myData), replace=TRUE, prob=c(0.7, 0.3))
trainData <- myData[ind == 1,]
testData<- myData[ind == 2,]
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
myFormula <- Y ~ X1 + X2 + X3 + ... + Xk
myData_ctree <- ctree(myFormula, data=trainData)
# Приведите матрицу классификации.
> table(predict(myData_ctree),
trainData$имя_выбранной_результативной_переменной)
Приведите результаты построения дерева решений в виде таблицы.
> print(myData_ctree)
Опишите последовательность проведения классификации с точки зрения переменных.
Приведите дерево решений на графике в общем виде.
> plot(myData_ctree)
Приведите дерево решений на графике в упрощенном виде.
> plot(myData_ctree, type="simple")
Дайте интерпретацию дерева решений с точки зрения листьев (терминальных узлов).
Опишите вероятности для каждого класса результативного признака, указав количество
наблюдений в каждом классе, с точки зрения значений параметров классифицирующих
признаков.
Сведите полученные выводы в небольшую аналитическую записку о результатах
классификации.
Примените полученное дерево решений для тестовых данных. Дайте общую характеристику
ошибкам классификации.
> testPred<-predict(myData_ctree, newdata=testData)
> table(testPred, testData$имя_выбранной_результативной_переменной)
setwd("C:/Users/GudievZK/Desktop/GitHub/DF/)
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
### Задание 1. ###
# Имеется фрагмент базы данных об анкетировании клиентов турфирмы. Разделите данные на обучающую и тестовую выборки по 70% и 30%,
# либо используя другие проценты по своему усмотрению.
# library(party)
set.seed(1234)
ind <- sample(2, nrow(myData), replace=TRUE, prob=c(0.7, 0.3))
trainData <- myData[ind == 1,]
testData<- myData[ind == 2,]
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
myFormula <- Y ~ X1 + X2 + X3 + ... + Xk
myData_ctree <- ctree(myFormula, data=trainData)
# Приведите матрицу классификации.
> table(predict(myData_ctree),
trainData$имя_выбранной_результативной_переменной)
Приведите результаты построения дерева решений в виде таблицы.
> print(myData_ctree)
Опишите последовательность проведения классификации с точки зрения переменных.
Приведите дерево решений на графике в общем виде.
> plot(myData_ctree)
Приведите дерево решений на графике в упрощенном виде.
> plot(myData_ctree, type="simple")
Дайте интерпретацию дерева решений с точки зрения листьев (терминальных узлов).
Опишите вероятности для каждого класса результативного признака, указав количество
наблюдений в каждом классе, с точки зрения значений параметров классифицирующих
признаков.
Сведите полученные выводы в небольшую аналитическую записку о результатах
классификации.
Примените полученное дерево решений для тестовых данных. Дайте общую характеристику
ошибкам классификации.
> testPred<-predict(myData_ctree, newdata=testData)
> table(testPred, testData$имя_выбранной_результативной_переменной)
remove(list = ls())
getwd()
setwd("C:/Users/GudievZK/Desktop/GitHub/DF/)
setwd("C:/Users/GudievZK/Desktop/GitHub/DF/)
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
### Задание 1. ###
# Имеется фрагмент базы данных об анкетировании клиентов турфирмы. Разделите данные на обучающую и тестовую выборки по 70% и 30%,
# либо используя другие проценты по своему усмотрению.
# library(party)
set.seed(1234)
ind <- sample(2, nrow(myData), replace=TRUE, prob=c(0.7, 0.3))
trainData <- myData[ind == 1,]
testData<- myData[ind == 2,]
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
myFormula <- Y ~ X1 + X2 + X3 + ... + Xk
myData_ctree <- ctree(myFormula, data=trainData)
# Приведите матрицу классификации.
> table(predict(myData_ctree),
trainData$имя_выбранной_результативной_переменной)
Приведите результаты построения дерева решений в виде таблицы.
> print(myData_ctree)
Опишите последовательность проведения классификации с точки зрения переменных.
Приведите дерево решений на графике в общем виде.
> plot(myData_ctree)
myData
ind <- sample(2, nrow(myData), replace=TRUE, prob=c(0.7, 0.3))
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
remove(list = ls())
library(party)
library(rpart)
library(randomForest)
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
remove(list = ls())
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
## Считаем данные ###
getwd()
set.seed(1234)
ind <- sample(2, nrow(myData), replace=TRUE, prob=c(0.7, 0.3))
ind
View(myData)
tourism
trainData <- myData[ind == 1, ]
testData<- myData[ind == 2, ]
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
myFormula <- Y ~ X1 + X2 + X3 + ... + Xk
View(myData)
myData_ctree <- ctree(myFormula, data=trainData)
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
str(myData)
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
library(dplyr)
str(myData)
select_if(myData, is.character)
names(select_if(myData, is.character))
factorNames <- names(select_if(myData, is.character))
sapply(myData, factorNames, as.factor)
lapply(myData[factorNames], as.factor)
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
str(myData)
lapply(myData[factorNames], as.factor)
lapply(myData[factorNames], factor)
myData <- lapply(myData[factorNames], factor)
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
str(myData)
View(myData)
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
set.seed(1234)
ind <- sample(2, nrow(myData), replace = TRUE, prob = c(0.7, 0.3)) #
trainData <- myData[ind == 1, ]
testData<- myData[ind == 2, ]
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
str(myData)
factorNames <- names(select_if(myData, is.character))
myData[, factorNames] <- lapply(myData[factorNames], factor)
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
str(myData)
myFormula <- myData$AGE ~ myData$COMPANIONS + myData$CHOICE + myData$LENGTH + myData$TIMES_YEAR +
+ myData$AIM + myData$EXPENCES + myData$ORGANIZE +
+ myData$TYPE + myData$HOTEL_QUAL
myFormula
myFormula <- myData
View(myFormula)
myData_ctree <- ctree(myFormula, data=trainData)
myData_ctree <- ctree(myFormula, data = Data)
myFormula <- trainData$AGE ~ trainData$COMPANIONS + trainData$CHOICE + trainData$LENGTH + trainData$TIMES_YEAR +
+ trainData$AIM + trainData$EXPENCES + trainData$ORGANIZE +
+ trainData$TYPE + trainData$HOTEL_QUAL
myFormula <- myData
View(myFormula)
myData_ctree <- ctree(myFormula, data = trainData)
# Постройте дерево решений на основе пакета party, выбрав интересующую Вас зависимую переменную. Поясните Ваш выбор.
# В частности, какую неизвестную информацию об исходных данных позволит получить построение дерева решений для этой переменной?
# Обозначьте зависимую переменную как Y, и классификационные переменные как Х1, Х2, и т.д., либо другим удобным способом.
# library(party)
str(myData)
trainData
View(testData)
View(trainData)
View(testData)
View(trainData)
myFormula <- trainData$AGE ~ trainData$COMPANIONS + trainData$CHOICE + trainData$LENGTH + trainData$TIMES_YEAR +
+ trainData$AIM + trainData$EXPENCES + trainData$ORGANIZE +
+ trainData$TYPE + trainData$HOTEL_QUAL
myData_ctree <- ctree(myFormula, data = trainData)
myFormula <- trainData$COMPANIONS ~ trainData$AGE + trainData$CHOICE + trainData$LENGTH + trainData$TIMES_YEAR +
+ trainData$AIM + trainData$EXPENCES + trainData$ORGANIZE +
+ trainData$TYPE + trainData$HOTEL_QUAL
myFormula <- myData
View(myFormula)
myData_ctree <- ctree(myFormula, data = trainData)
remove(list = ls())
myData <- read.csv("C:/Users/GudievZK/Desktop/GitHub/DF/tourism.csv")
set.seed(1234)
ind <- sample(2, nrow(myData), replace = TRUE, prob = c(0.7, 0.3)) #
trainData <- myData[ind == 1, ]
testData<- myData[ind == 2, ]
factorNames <- names(select_if(myData, is.character))
myData[, factorNames] <- lapply(myData[factorNames], factor)
myFormula <- trainData$AGE ~ trainData$COMPANIONS + trainData$CHOICE + trainData$LENGTH + trainData$TIMES_YEAR +
+ trainData$AIM + trainData$EXPENCES + trainData$ORGANIZE +
+ trainData$TYPE + trainData$HOTEL_QUAL
myFormula <- myData
myData_ctree <- ctree(myFormula, data = trainData)
