)
filled.contour(as.matrix(myData[, c(1, 2, 4)]), color=terrain.colors, asp=1
#, plot.axes=contour(as.factor(myData[, 1:4]), add=T)
)
filled.contour(as.matrix(myData[, c(3, 4, 1)]), color=terrain.colors, asp=1
#, plot.axes=contour(as.factor(myData[, 1:4]), add=T)
)
filled.contour(as.matrix(myData[, c(3, 4, 5)]), color=terrain.colors, asp=1
# , plot.axes=contour(as.matrix(myData[, 3]), as.matrix(myData[, 4]), z = as.matrix(myData[, 5]), add=T)
)
persp(is.matrix(myData[, 1:3]),
theta = 25, phi = 30, expand = 0.5, col="lightblue")
library(MASS)
parcoord(myData[1:4], col=as.factor(myData[, 5]))
# функция показывает текущую рабочую директорию
getwd()
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
myData <- read.table(file="/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/iris_example.csv", dec=",", sep=",", header=TRUE)
# myData <- edit(myData)
head(myData)
sum(is.na(myData))
myData[!complete.cases(myData),]
library(zoo)
# поскольку колонки являются количественными показателями,
myData[] <- lapply(myData, na.aggregate)
sum(is.na(myData))
dim(myData)
str(myData)
library(dplyr)
colnames(select_if(myData, is.numeric))
colnames(select_if(myData, is.character))
dim(myData)
str(myData)
attributes(myData)
summary(myData)
# библиотека с функцией Винзор
library(psych)
# выделяем каждую численную колонку в отдельную переменную и считаем для нее винзорированное среднее
x1 <- myData[, "SEPALLEN"]
winsor.mean(x1, trim = 0.2, na.rm = TRUE)
x2 <- myData[, "SEPALWID"]
winsor.mean(x2, trim = 0.2, na.rm = TRUE)
x3 <- myData[, "PETALLEN"]
winsor.mean(x3, trim = 0.2, na.rm = TRUE)
x4 <- myData[, "PETALWID"]
winsor.mean(x4, trim = 0.2, na.rm = TRUE)
boxplot.stats(x1)$out
boxplot(x1)
boxplot.stats(x2)$out
boxplot(x2)
boxplot.stats(x3)$out
boxplot(x3)
boxplot.stats(x4)$out
boxplot(x4)
# функция показывает текущую рабочую директорию
getwd()
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
myData <- read.table(file="/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/iris_example.csv", dec=",", sep=",", header=TRUE)
# myData <- edit(myData)
head(myData)
sum(is.na(myData))
myData[!complete.cases(myData),]
library(zoo)
# поскольку колонки являются количественными показателями,
myData[] <- lapply(myData, na.aggregate)
sum(is.na(myData))
dim(myData)
str(myData)
library(dplyr)
colnames(select_if(myData, is.numeric))
colnames(select_if(myData, is.character))
dim(myData)
str(myData)
attributes(myData)
summary(myData)
# библиотека с функцией Винзор
library(psych)
# выделяем каждую численную колонку в отдельную переменную и считаем для нее винзорированное среднее
x1 <- myData[, "SEPALLEN"]
winsor.mean(x1, trim = 0.2, na.rm = TRUE)
x2 <- myData[, "SEPALWID"]
winsor.mean(x2, trim = 0.2, na.rm = TRUE)
x3 <- myData[, "PETALLEN"]
winsor.mean(x3, trim = 0.2, na.rm = TRUE)
x4 <- myData[, "PETALWID"]
winsor.mean(x4, trim = 0.2, na.rm = TRUE)
boxplot.stats(x1)$out
boxplot(x1)
boxplot.stats(x2)$out
boxplot(x2)
boxplot.stats(x3)$out
boxplot(x3)
boxplot.stats(x4)$out
boxplot(x4)
df <- data.frame(x1, x2, x3, x4)
# rm(x1, x2, x3, x4)
attach(df) # attach позволяет обращаться к переменным x1,x2,x3,x4 дата фрейма df без необходимости указвать наименования дата фрейма x1
(a <- which(x1 %in% boxplot.stats(x1)$out))
(b <- which(x2 %in% boxplot.stats(x2)$out))
(c <- which(x3 %in% boxplot.stats(x3)$out))
(d <- which(x3 %in% boxplot.stats(x4)$out))
detach(df)
(outlier.list1 <- Reduce(intersect, list(a, b, c, d)))
(outlier.list2 <- Reduce(union, list(a, b, c, d)))
myData2 <- myData[,1:4]
kmeans.result <- kmeans(myData2, centers = 3)
kmeans.result$centers
centers <- kmeans.result$centers[kmeans.result$cluster, ]
distances <- sqrt(rowSums((myData2 - centers)^2))
outliers <- order(distances, decreasing=T)[1:5]
print(outliers)
print(myData2[outliers,])
plot(myData2[, c("SEPALLEN", "SEPALWID")], pch = "o", col = kmeans.result$cluster, cex = 1.2)
points(kmeans.result$centers[, c("SEPALLEN", "SEPALWID")], col = 1:3, pch = 8, cex = 1.5, lwd = 4)
points(myData2[outliers, c("SEPALLEN", "SEPALWID")], pch = "+", col = 4, cex = 1.7)
plot(myData2[, c("PETALLEN", "PETALWID")], pch = "o", col = kmeans.result$cluster, cex = 1.2)
points(kmeans.result$centers[, c("PETALLEN", "PETALWID")], col = 1:3, pch = 8, cex = 1.5, lwd = 4)
points(myData2[outliers, c("PETALLEN", "PETALWID")], pch = "+", col = 4, cex = 1.7)
boxplot(x1)
boxplot(x2)
boxplot(x3)
boxplot(x4)
hist(x1)
hist(x2)
hist(x3)
hist(x4)
pairs(~ x1 + x2 + x3 + x4)
distMatrix <- as.matrix(dist(myData[, 1:4]))
heatmap(distMatrix)
library(lattice)
myData[, 5] <- as.factor(myData[, 5])
levelplot(IRISTYPE ~ SEPALLEN * SEPALWID, myData, cuts = 9, col.regions = grey.colors(10)[10:1])
levelplot(IRISTYPE ~ PETALLEN * PETALWID, myData, cuts = 9, col.regions = grey.colors(10)[10:1])
levelplot(SEPALLEN ~ PETALLEN * PETALWID, myData, cuts = 9, col.regions = grey.colors(10)[10:1])
filled.contour(as.matrix(myData[, 1:3]), color=terrain.colors, asp=1
#, plot.axes=contour(as.factor(myData[, 1:4]), add=T)
)
filled.contour(as.matrix(myData[, c(1, 2, 4)]), color=terrain.colors, asp=1
#, plot.axes=contour(as.factor(myData[, 1:4]), add=T)
)
filled.contour(as.matrix(myData[, c(3, 4, 1)]), color=terrain.colors, asp=1
#, plot.axes=contour(as.factor(myData[, 1:4]), add=T)
)
filled.contour(as.matrix(myData[, c(3, 4, 5)]), color=terrain.colors, asp=1
# , plot.axes=contour(as.matrix(myData[, 3]), as.matrix(myData[, 4]), z = as.matrix(myData[, 5]), add=T)
)
persp(is.matrix(myData[, 1:3]),
theta = 25, phi = 30, expand = 0.5, col="lightblue")
str(myData)
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DataMining")
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
myData <- read.table(file="/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/iris_example.csv", dec=",", sep=",", header=TRUE)
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv", stringsAsFactors = TRUE)
View(myData)
ind <- sample(2, nrow(myData),
replace = TRUE,
prob=c(0.7, 0.3))
ind
length(ind)
length(ind[ind == 1])
length(ind[ind == 2])
table(ind)
prop.table(ind)
trainData <- myData[ind == 1, ]
testData <- myData[ind == 2, ]
table(predict(myData_ctree), trainData$EXPENCES)
myFormula <- EXPENCES ~ LENGTH + TYPE + HOTEL_QUAL + AIM + COMPANIONS + AGE + ORGANIZE
myData_ctree <- ctree(myFormula, data = trainData)
library(party)
install.packages("party")
# install.packages("party")
library(party)
# install.packages("party")
library(party)
# install.packages("party")
library("party")
myFormula <- EXPENCES ~ LENGTH + TYPE + HOTEL_QUAL + AIM + COMPANIONS + AGE + ORGANIZE
myData_ctree <- ctree(myFormula, data = trainData)
# библиотеки
library(xgboost)
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
# библиотеки
library(xgboost)
install.packages("xgboost")
install.packages("xgboost")
install.packages("xgboost")
# библиотеки
library(xgboost)
library(xgboost)
install.packages("caTools")
install.packages("dplyr")
install.packages("party")
install.packages("party")
# install.packages("party")
library("party")
# install.packages("party")
library(party)
install.packages("party")
library(party)
install.packages("xgboost")
# библиотеки
library(xgboost)
install.packages("caTools")
library(caTools)
library(caret)
install.packages("caret")
install.packages("caret")
# библиотеки
library(xgboost)
library(caTools)
library(dplyr)
library(caret)
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
# функция задает текущую рабочую директорию
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
# библиотеки
library(xgboost)
library(caTools)
library(dplyr)
library(caret)
# setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/)
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
remove(list = ls())
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
filename <- paste0(path_dir, "tourism.csv")
myData <- read.csv(filename)
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
filename <- paste0(path_dir, "tourism.csv")
myData <- read.csv(filename)
remove(list = ls())
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
# filename <- paste0(path_dir, "tourism.csv")
# myData <- read.csv(filename)
head(myData)
str(myData)
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
# filename <- paste0(path_dir, "tourism.csv")
# myData <- read.csv(filename)
head(myData)
str(myData)
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
# filename <- paste0(path_dir, "tourism.csv")
# myData <- read.csv(filename)
head(myData)
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
# filename <- paste0(path_dir, "tourism.csv")
# myData <- read.csv(filename)
head(myData)
str(myData)
myData[]<-lapply(myData, factor)
str(myData)
sample_split <- sample.split(Y = myData$TYPE, SplitRatio = 0.7)
train_set <- subset(x = myData, sample_split == TRUE)
test_set <- subset(x = myData, sample_split == FALSE)
y_train <- as.integer(train_set$TYPE) - 1
y_test <- as.integer(test_set$TYPE) - 1
X_train <- train_set %>% select(-TYPE)
X_test <- test_set %>% select(-TYPE)
sample_split
length(sample_split)
table(sample_split)
prop.table(sample_split)
sample_split
View(myData)
prop(sample_split)
prop(table(sample_split))
sample_split <- sample.split(Y = myData$TYPE, SplitRatio = 0.7)
train_set <- subset(x = myData, sample_split == TRUE)
test_set <- subset(x = myData, sample_split == FALSE)
y_train <- as.integer(train_set$TYPE) - 1
y_test <- as.integer(test_set$TYPE) - 1
X_train <- train_set %>% select(-TYPE)
X_test <- test_set %>% select(-TYPE)
sample_split <- sample.split(Y = myData$TYPE, SplitRatio = 0.7)
train_set <- subset(x = myData, sample_split == TRUE)
test_set <- subset(x = myData, sample_split == FALSE)
y_train <- as.integer(train_set$TYPE) - 1
y_test <- as.integer(test_set$TYPE) - 1
X_train <- train_set %>% select(-TYPE)
X_test <- test_set %>% select(-TYPE)
y_train
y_test
X_train
X_test
train_set
X_train
xgb_train
xgb_train <- xgb.DMatrix(data = as.matrix(sapply(X_train, as.numeric)), label = y_train)
xgb_train
xgb_test
xgb_train <- xgb.DMatrix(data = as.matrix(sapply(X_train, as.numeric)), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(sapply(X_test, as.numeric)), label = y_test)
xgb_test
xgb_train
# библиотеки
library(xgboost)
library(caTools)
library(dplyr)
library(caret)
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
# path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
myData <- read.csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/tourism.csv")
# filename <- paste0(path_dir, "tourism.csv")
# myData <- read.csv(filename)
head(myData)
str(myData)
myData[]<-lapply(myData, factor)
str(myData)
set.seed(1234)
sample_split <- sample.split(Y = myData$TYPE, SplitRatio = 0.7)
train_set <- subset(x = myData, sample_split == TRUE)
test_set <- subset(x = myData, sample_split == FALSE)
y_train <- as.integer(train_set$TYPE) - 1
y_test <- as.integer(test_set$TYPE) - 1
X_train <- train_set %>% select(-TYPE)
X_test <- test_set %>% select(-TYPE)
xgb_train <- xgb.DMatrix(data = as.matrix(sapply(X_train, as.numeric)), label = y_train)
xgb_test <- xgb.DMatrix(data = as.matrix(sapply(X_test, as.numeric)), label = y_test)
xgb_params <- list(
booster = "gbtree",
eta = 0.01,
max_depth = 8,
gamma = 4,
subsample = 0.75,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = length(levels(myData$TYPE))
)
xgb_model <- xgb.train(
params = xgb_params,
data = xgb_train,
nrounds = 5000,
verbose = 1
)
xgb_model
xgb_preds <- predict(xgb_model, as.matrix(sapply(X_test, as.numeric)), reshape = TRUE)
xgb_preds <- as.data.frame(xgb_preds)
colnames(xgb_preds) <- levels(myData$TYPE)
xgb_preds
original_levels <- myData$TYPE %>% levels()
xgb_preds$PredictedClass <- apply(xgb_preds, 1, function(y) colnames(xgb_preds)[which.max(y)]) %>%
factor(levels = original_levels)
xgb_preds$ActualClass <- original_levels[y_test + 1] %>%
factor(levels = original_levels)
xgb_preds
accuracy <- sum(xgb_preds$PredictedClass == xgb_preds$ActualClass) / nrow(xgb_preds)
accuracy
confusionMatrix(xgb_preds$ActualClass, xgb_preds$PredictedClass)
library(readr)
library(dplyr)
path_dir <- getwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
path_dir <- getwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors<-read_csv(paste0(path_dir, "/actors.csv"))
actors<-read_csv(paste0(path_dir, "/actors.csv"))
library(readr)
library(dplyr)
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors<-read_csv(paste0(path_dir, "/actors.csv"))
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors<-read_csv(paste0(path_dir, "/actors.csv"))
paste0(path_dir, "/actors.csv")
library(readr)
library(dplyr)
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors<-read_csv(paste0(path_dir, "/actors.csv"))
path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors<-read_csv(paste0(path_dir, "/actors.csv"))
movies<-read_csv(paste0(path_dir, "/movies.csv"))
# path_dir <- setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
# actors <- read_csv(paste0(path_dir, "/actors.csv"))
# movies <- read_csv(paste0(path_dir, "/movies.csv"))
actors <- read_csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/actors.csv")
movies <- read_csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/movies.csv")
View(actors)
View(movies)
View(actors)
View(movies)
library(igraph)
library(igraph)
myGraph <- graph_from_data_frame(d = movies, vertices = actors, directed = F)
set.seed(100)
library(igraph)
library("igraph")
library(igraph)
library(party)
library(igraph)
str(Titanic)
df<- as.data.frame(Titanic)
titanic.raw <- NULL
for(i in 1:4) {titanic.raw <- cbind(titanic.raw, rep(as.character(df[,i]), df$Freq))}
titanic.raw <- as.data.frame(titanic.raw)
names(titanic.raw) <- names(df)[1:4]
dim(titanic.raw)
summary(titanic.raw)
str(titanic.raw)
names(titanic.raw) <- c("Class", "Sex", "Age", "Survived")
library(arules)
library(arules)
install.packages("arules")
install.packages("arules")
install.packages("arules")
library(party)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages(pkgs = c("party", "igraph"), dependencies=TRUE)
library(readr)
library(igraph)
actors <- read_csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/actors.csv")
getwd()
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/")
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors <- read_csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/actors.csv")
library(dplyr)
actors <- read_csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/actors.csv")
library(readr)
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining")
actors <- read_csv("/Users/zelimkhan/Desktop/Data/GitHub/DF/DataMining/actors.csv")
remove(list = ls())
actors <- read_csv(paste0(path_dir, "/actors.csv"))
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
library(ggplot2)
library(psych)
library(dplyr)
library(readxl)
library(ROCR)
library(ggplot2)
library(psych)
library(dplyr)
library(readxl)
library(ROCR)
yt <- read.csv2("yt.csv")
yt <- read_xlsx("plan.xlsx")
# setwd("C:/Users/GudievZK/Desktop/GitHub/DF/")
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/")#
yt <- read.csv2("yt.csv")
yt <- read_xlsx("plan.xlsx")
yt <- read_xlsx("plan.xlsx")
yt <- read_excel("/Users/zelimkhan/Desktop/Data/GitHub/DF/plan.xlsx")
View(yt)
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/")
yt <- read_xlsx('/Users/zelimkhan/Desktop/Data/GitHub/DF/plan.xlsx', sheet = 'Worksheet')
# Удаление ненужных столбцов
names(yt)
yt <- select(yt, "ID задачи", "Заголовок", "Основание", "План по стандартизации", "Квартал", "Вид ТЗ", "Stage",
"Количество возвратов от ДЭПиР", "Количество возвратов от ОИВ", "Исполнитель", "Руководитель группы",
"Курирующий заместитель руководителя ПО", "Исполнитель ДЭПиР", "Контракт", "ПЦП", "Критерии оценки",
"Форма 2", "Способы определения поставщика (подрядчика, исполнителя)", "Теги", "КТД", "Дата создания",
"Время нахождения в статусе \"В работе АЦ\"", "Время нахождения в статусе \"Доработка ОИВ\"",
"Время нахождения в статусе \"Доработка ДЭПиР\"", "Время нахождения в статусе \"Внут. согл.\"",
"Время нахождения в статусе \"В ДЭПиР\"", "Время нахождения в статусе \"На согл. в ОИВ\"",
"Время нахождения в статусе \"Подготовка к РГ\"", "Время нахождения в статусе \"РГ\"",
"Время нахождения в статусе \"МРГ\"", "Время нахождения в статусе \"Загрузка в ЕАИСТ\"",
"Длительность")
yt <- filter(yt, yt$Теги != "Не полностью YouTrackная")
yt <- filter(yt, yt$Stage == "Завершено")
yt <- select(yt, "ID задачи", "Заголовок", "Основание", "План по стандартизации", "Квартал", "Вид ТЗ", "Stage",
"Количество возвратов от ДЭПиР", "Количество возвратов от ОИВ", "Исполнитель", "Руководитель группы",
"Курирующий заместитель руководителя ПО", "Исполнитель ДЭПиР", "Контракт", "ПЦП", "Критерии оценки",
"Форма 2", "Способы определения поставщика (подрядчика, исполнителя)", "Теги", "КТД", "Дата создания",
"Время нахождения в статусе \"В работе АЦ\"", "Время нахождения в статусе \"Доработка ОИВ\"",
"Время нахождения в статусе \"Доработка ДЭПиР\"", "Время нахождения в статусе \"Внут. согл.\"",
"Время нахождения в статусе \"В ДЭПиР\"", "Время нахождения в статусе \"На согл. в ОИВ\"",
"Время нахождения в статусе \"Подготовка к РГ\"", "Время нахождения в статусе \"РГ\"",
"Время нахождения в статусе \"МРГ\"", "Время нахождения в статусе \"Загрузка в ЕАИСТ\"",
"Длительность")
yt <- rename(yt,
id = "ID задачи", name = "Заголовок", reason = "Основание", year_plan_st = "План по стандартизации",
kvartal = "Квартал", kind_tz = "Вид ТЗ", stage = "Stage", numb_ret_depir = "Количество возвратов от ДЭПиР",
numb_ret_oiv = "Количество возвратов от ОИВ", executor_ac = "Исполнитель", teamleader = "Руководитель группы",
deputy = "Курирующий заместитель руководителя ПО", executor_depir = "Исполнитель ДЭПиР", contract = "Контракт",
pcp = "ПЦП", criteria = "Критерии оценки", f2 = "Форма 2", method = "Способы определения поставщика (подрядчика, исполнителя)",
tegs = "Теги", ktd = "КТД", created_date = "Дата создания", time_ac = "Время нахождения в статусе \"В работе АЦ\"",
time_rev_oiv = "Время нахождения в статусе \"Доработка ОИВ\"", time_rev_depir = "Время нахождения в статусе \"Доработка ДЭПиР\"",
time_vn_sogl = "Время нахождения в статусе \"Внут. согл.\"", time_depir = "Время нахождения в статусе \"В ДЭПиР\"",
time_oiv = "Время нахождения в статусе \"На согл. в ОИВ\"", time_prep_rg = "Время нахождения в статусе \"Подготовка к РГ\"",
time_rg = "Время нахождения в статусе \"РГ\"", time_mrg = "Время нахождения в статусе \"МРГ\"",
time_eaist = "Время нахождения в статусе \"Загрузка в ЕАИСТ\"", duration = "Длительность")
names(yt)
str(yt)
# корректирорвка типов
yt_n_names <- c('numb_ret_depir', 'numb_ret_oiv', 'time_plan', 'time_ac', 'time_rev_oiv',
'time_rev_depir', 'time_vn_sogl', 'time_depir', 'time_oiv',
'time_prep_rg', 'time_rg', 'time_mrg', 'time_eaist', 'duration')
yt[, yt_n_names] <- lapply(yt[, yt_n_names], as.numeric)
yt_f_names <- c('reason', 'year_plan_st', 'kvartal', 'kind_tz', 'stage', 'executor_ac',
'teamleader', 'deputy', 'executor_depir', 'contract', 'pcp', 'criteria',
'f2', 'method', 'tegs')
yt[yt_f_names] <- lapply(yt[yt_f_names], as.factor)
write.csv2(yt, file = "yt.csv")
write.csv2(yt, file = "yt.csv")
write.csv2(yt, file = "yt.csv")
write.csv2(yt, file = "yt.csv")
write.csv2(yt, file = "yt1.csv")
View(yt)
library(readxl)
write.table(yt, file = "yt1.xlsx")
