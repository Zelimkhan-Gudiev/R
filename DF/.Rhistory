library(googlesheets4)
# данные для теста
my_iris   <- iris
my_mtcars <- mtcars
# создаём докс
ss <- sheets_create("demo_dox",
sheets = list(iris   = head(my_iris),
mtcars = my_mtcars))
# создаём докс
ss <- gs4_create("demo_dox",
sheets = list(iris   = head(my_iris),
mtcars = my_mtcars))
# открыть созданный Google Dox
gs4_browse(ss)
# создать новый лист
sheet_add(ss,
sheet = "mtcars_new",
.after = "mtcars")
# запись данных на новый лист
sheet_write(data = my_iris,
ss = ss,
sheet = "iris_new")
# дописать значиения
sheet_append(data  = tail(my_iris, 20),
ss    = ss,
sheet = "iris")
# получить список листок google таблицы
sheet_names(ss)
# чтение листа из гугл таблиц
ss2 <- as_sheets_id("17dRz4AYgfQvpTI6J6p9AYjrVuC-gTRj7BM4MzgAxIKY")
ss2
data <- sheets_read(ss2,
sheet = "iris_new")
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1VOKDMjL2LoasWjF7w1kSkKz71VyVDr03")
dolya <- sheets_read(dolya,
sheet = "dolya")
dolya <- sheet_read(dolya,
sheet = "dolya")
dolya <- read_sheet(dolya,
sheet = "dolya")
dolya
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1VOKDMjL2LoasWjF7w1kSkKz71VyVDr03")
dolya <- read_sheet(dolya,
sheet = "dolya")
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1VOKDMjL2LoasWjF7w1kSkKz71VyVDr03")
dolya <- read_sheet(dolya,
sheet = "Export Worksheet")
dolya
dolya <- read_sheet(dolya,
sheet = "Export Worksheet")
dolya_s <- read_sheet(dolya,
sheet = "Export Worksheet")
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1VOKDMjL2LoasWjF7w1kSkKz71VyVDr03")
dolya_s <- read_sheet(dolya,
sheet = "Export Worksheet")
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1VOKDMjL2LoasWjF7w1kSkKz71VyVDr03")
dolya_s <- read_sheet(dolya,
sheet = "Export Worksheet")
dolya_s <- range_read(dolya, shett = "Export Worksheet")
dolya_s <- range_read(dolya, sheet = "Export Worksheet")
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1_HvhGAXsk2_s161Jmv01emFqmKaEr3aZ")
dolya_s <- read_sheet(dolya,
sheet = "Export Worksheet")
dolya_s <- range_read(dolya, sheet = "Export Worksheet")
# чтение листа из гугл таблиц
dolya <- as_sheets_id("1ltR2wYrmN1tPla6TJfvpvG-IwInB_43Gth_4Ywws5S8")
dolya_s <- read_sheet(dolya,
sheet = "Export Worksheet")
dolya_s <- range_read(dolya, sheet = "Export Worksheet")
View(dolya_s)
dolya <- range_read(dolya, sheet = "Export Worksheet")
names(dolya)
delAndSt <- subset(dolya, IS_STANDARD_PRODUCT == 2)
View(delAndSt)
condStand <- subset(dolya, IS_STANDARD_PRODUCT %in% c(2, 4, 5, 51, 6))
View(condStand)
cor(iris[, -5])
remove(list = ls())
library(ggplot2)
library(psych)
library(dplyr)
library(readxl)
setwd("/Users/zelimkhan/Desktop/Data/GitHub/DF/")#
yt <- read.csv2("yt.csv")
fit <- lm(Fertility ~ Examination + Catholic, data = swiss)
fit
summary(fit)
ytFit <- lm(duration ~ kind_tz, yt)
summary(ytFit)
aggregate(duration ~ kind_tz, yt, mean)
test_data <- read.csv("https://stepic.org/media/attachments/course/129/fill_na_test.csv")
View(test_data)
predict(fit, test_data)
fit <- lm(y ~ x_1 + x_2, test_data)
fit
summary(fit)
predict(fit, test_data)
fit <- lm(y ~ x_1 + x_2, x)
fit <- lm(y ~ x_1 + x_2, x)
fill_na <- function(x) {
fit <- lm(y ~ x_1 + x_2, x)
}
y[y != 'NA']
x <- test_data <- read.csv("https://stepic.org/media/attachments/course/129/fill_na_test.csv")
fit <- lm(y ~ x_1 + x_2, x)
x$y_full <- x$y[x$y != 'NA']
x$y[x$y != 'NA']
View(x)
x$y_full[x$y_full == "NA"]
x$y_full[x$y_full == "NA"] <- predict(fit, x)
x$y_full[x$y_full == "NA"] <- predict(fit, x)
x$y_full[x$y_full == "NA"]
fit$fitted.values
predict(fit, test_data)
fitV <- fit$fitted.values
x$y_full[x$y_full == "NA"] <- fitV
x$y_full[x$y_full == "NA"]
x$y_full[x$y_full == "NA"] <- 0
View(x)
x$y_full[x$y_full == "NA"] <- 0
View(x)
View(x)
x$y_full[x$y_full == "NA"]
subset(x, x$y_full == "NA")
subset(x, x$y_full = "NA")
subset(x, x$y_full == "NA")
x$y_full[, x$y_full == "NA"]
x[, x$y_full == "NA"]
attitude
df7 <- attitude
remove(list = ls())
library(ggplot2)
library(psych)
library(dplyr)
library(readxl)
df7 <- attitude
names(df7)
fit <- lm(rating ~ complaints * critical, df17)
fit <- lm(rating ~ complaints * critical, df7)
summary(fit)
names(df7)
x <- test_data <- read.csv("https://stepic.org/media/attachments/course/129/fill_na_test.csv")
####  Step 5 of 15 ####
# не правильная функция
fill_na <- function(x) {
fit <- lm(y ~ x_1 + x_2, x)
x$y_full <- predict(fit, subset(x, y != "NA"))
x$y_full <- ifelse(is.na(x$y), x$y_full, x$y)
return(x)
}
fill_na(x)
####  Step 6 of 15 ####
mtcars <- mtcars
df <- mtcars[, c(mtcars$wt, mtcars$mpg, mtcars$disp, mtcars$drat, mtcars$hp)]
df <- mtcars[, c(mtcars$wt, mtcars$mpg, mtcars$disp, mtcars$drat, mtcars$hp)]
which(mtcars, с(mtcars$wt, mtcars$mpg, mtcars$disp, mtcars$drat, mtcars$hp)
hist(swiss$Catholic, col = 'red')
swiss$religious <- ifelse(swiss$Catholic > 60, 'Lots', 'Few')
swiss
hist(swiss$Catholic, col = 'red')
####  Step 6 of 15 ####
# В переменной df сохранен subset данных mtcars только с переменными "wt", "mpg", "disp", "drat", "hp".
# Воспользуйтесь множественным регрессионным анализом, чтобы предсказать вес машины (переменная "wt").
# Выберите такую комбинацию независимых переменных (из "mpg", "disp", "drat", "hp"), чтобы значение R^2 adjusted было наибольшим.
# Взаимодействия факторов учитывать не надо.
# Выполните все операции по сравнению моделей на вашем компьютере.
# В поле для ответа сохраните в переменную  model регрессионную модель с оптимальной комбинацией предикторов!
df <- mtcars
df <- select(df, wt, mpg, disp, drat, hp)
df
mtcars
model <- lm(wt ~, df)
model <- lm(wt ~ wt + mpg + disp + hp, df)
model
df1 <- mtcars[,c("wt", "mpg", "disp", "drat", "hp")]
df1 <- mtcars[,c("wt", "mpg", "disp", "drat", "hp")]
fit_full <- lm(wt ~ ., data = df1)
fit_full
summary(fit_full)
optimal_fit <-  step(fit_full, direction = 'backward')
optimal_fit
opt_summary <- summary(optimal_fit)
attr(as.formula(opt_summary), "term.labels")
opt_summary
attr(as.formula(opt_summary), "term.labels")
lm(wt ~, df)
#4
# ссылка на коммент ниже, кот-й помог решить без перебора вариантов:
# https://stepik.org/lesson/11509/step/6?discussion=82172&reply=82441&unit=2532
# подробней:
#  1) установить пакет leaps
library(leaps)
b <- regsubsets(wt~., data = df, nbest = 4)
b
#(все комбинации для 4-х независимых переменных + Intercept)
plot(b, scale = "adjr2")
names(adj.r.sqrt)[which.max(adj.r.sqrt)]
library(leaps)
b <- regsubsets(wt~., data = df, nbest = 4)
#(все комбинации для 4-х независимых переменных + Intercept)
plot(b, scale = "adjr2")
# выбираем независимые переменные из верхнего (наибольшее adjr2) значения графика и подставляем их в модель:
model <- lm(wt ~ mpg + disp + hp, df)
# Ну и можно заглянуть в конец урока - файла (я не догадался ( ), тогда через
fit_full  <-  lm(wt ~., df)  # регрессия по всем независимым переменным
optimal_fit <-  step(fit_full, direction = 'backward')
ggplot(swiss, aes(x = Examination, y = Fertility)) +
geom_point()
ggplot(swiss, aes(x = Examination, y = Fertility)) +
geom_point() +
geom_smooth()
ggplot(swiss, aes(x = Examination, y = Fertility)) +
geom_point() +
geom_smooth(method = 'lm')
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()  +
geom_smooth()
ggplot(swiss, aes(x = Examination, y = Fertility, col = religious)) +
geom_point()  +
geom_smooth(method = 'lm')
# В этом примере будем работать с хорошо вам известным встроенным датасетом mtcars.
# Переменная am говорит о том, какая коробка передач используется в машине: 0 - автоматическая, 1 - ручная.
# Сделаем эту переменную факторной.
mtcars$am <- factor(mtcars$am, labels = c('Automatic', 'Manual'))
# В этом примере будем работать с хорошо вам известным встроенным датасетом mtcars.
# Переменная am говорит о том, какая коробка передач используется в машине: 0 - автоматическая, 1 - ручная.
# Сделаем эту переменную факторной.
mtcars <- mtcars
str(mtcars)
mtcars$am <- factor(mtcars$am, labels = c('Automatic', 'Manual'))
str(mtcars)
fit13 <- lm(mpg ~ wt * am, mtcars)
summary(fit13)
ggplot(mtcars, aes(y = mpg, x = wt, col = am)) +
geom_point()
ggplot(mtcars, aes(y = mpg, x = wt, col = am)) +
geom_point() +
geom_smooth()
ggplot(mtcars, aes(y = mpg, x = wt, col = am)) +
geom_point() +
geom_smooth('lm')
ggplot(mtcars, aes(y = mpg, x = wt, col = am)) +
geom_point() +
geom_smooth('lm')
ggplot(mtcars, aes(y = mpg, x = wt, col = am)) +
geom_point() +
geom_smooth(method = 'lm')
summary(fit13)
mtcars$am <- factor(mtcars$am)
# теперь строим график
my_plot <- ggplot(mtcars, aes(y = mpg, x = wt, col = am)) +
geom_smooth(method = 'lm')
my_plot
remove(list = ls())
swiss
attach(swiss)
swiss <- swiss
names(swiss)
str(swiss)
summary(swiss)
fit_full <- lm(Fertility ~ . data = swiss)
fit_full <- lm(Fertility ~ ., data = swiss)
summary(fit_full)
names(swiss)
fit_reduced1 <- lm(Fertility ~ Infant.Mortality + Examination + Catholic + Education, data = swiss)
summary(fit_reduced1)
summary(fit_full)
summary(fit_reduced1)
anova(fit_full, fit_reduced1)
names(swiss)
fit_reduced2 <- lm(Fertility ~ Infant.Mortality + Agriculture + Catholic + Education, data = swiss)
summary(fit_reduced2)
anova(fit_full, fit_reduced2)
step(fit_full, direction = 'backward')
optimal_fit <- step(fit_full, direction = 'backward')
summary(optimal_fit)
####  Step 4  of 6 ####
model_full <- lm(rating ~ ., data = attitude)
model_null <- lm(rating ~ 1, data = attitude)
attitude
summary(model_full)
summary(model_null)
scope = list(lower = model_null, upper = model_full)
scope
####  Step 4  of 6 ####
attitude <- attitude
names(attitude)
str(attitude)
scope = list(lower = model_null, upper = model_full)
scope
ideal_model <- step(model_null, scope = list(lower = model_null, upper = model_full), direction = 'forward')
summary(ideal_model)
anova(fit_full, ideal_model)
summary(ideal_model)
####  Step 5  of 6 ####
ideal_model <- lm(formula = rating ~ complaints + learning, data = attitude)
anova(fit_full, ideal_model)
####  Step 5  of 6 ####
ideal_model <- lm(formula = rating ~ complaints + learning, data = attitude)
ideal_model <- step(model_null, scope = list(lower = model_null, upper = model_full), direction = 'forward')
anova(fit_full, ideal_model)
summary(anova(fit_full, ideal_model))
anova(fit_full, ideal_model)
ideal_model <- step(model_null, scope = list(lower = model_null, upper = model_full), direction = 'forward')
anova(fit_full, ideal_model)
anova(model_full, ideal_model)
lcs <- LifeCycleSavings
remove(list = ls())
library(ggplot2)
library(psych)
library(dplyr)
library(readxl)
lcs <- LifeCycleSavings
str(lcs)
View(lcs)
fit6 <- lm(sr ~ ., lcs)
summary(fit6)
step(fit6, direction = 'backward')
fit6 <- lm(sr ~ (.)^2, lcs)
fit6
summary(fit6)
yt <- read.csv2("yt.csv")
ytFut <- lm(duration ~ ., yt)
data(swiss)
str(swiss)
# relationships between all variables
pairs(swiss)
ggplot(swiss, aes(x = Examination, y = Education)) +
geom_point()
ggplot(swiss, aes(x = Examination, y = Education)) +
geom_point() +
geom_smooth(method = 'lm')
ggplot(swiss, aes(x = Examination)) +
geom_histogram()
ggplot(swiss, aes(x = Education)) +
geom_histogram()
ggplot(swiss, aes(x = Examination, y = Education)) +
geom_point() +
geom_smooth()
lm1 <- lm(Education ~ Examination, swiss)
summary(lm1)
my_vector <- c(0.027, 0.079, 0.307, 0.098, 0.021, 0.091, 0.322, 0.211, 0.069, 0.261, 0.241, 0.166, 0.283, 0.041,
0.369, 0.167, 0.001, 0.053, 0.262, 0.033, 0.457, 0.166, 0.344, 0.139, 0.162, 0.152, 0.107, 0.255,
0.037, 0.005, 0.042, 0.220, 0.283, 0.050, 0.194, 0.018, 0.291, 0.037, 0.085, 0.004, 0.265, 0.218,
0.071, 0.213, 0.232, 0.024, 0.049, 0.431, 0.061, 0.523)
ggplot(my_vector, aes(x = my_vector)) +
geom_histogram()
ggplot(my_vector, aes(x = my_vector, y = frequency)) +
geom_histogram()
ggplot(my_vector, aes(x = my_vector, y = freq)) +
geom_histogram()
hist(my_vector)
ggplot(my_vector, aes(x = my_vector)) +
geom_histogram()
ggplot(my_vector, aes(x = my_vector)) +
geom_histogram()
ggplot(my_vector, aes(x = my_vector)) +
geom_histogram()
ggplot(swiss, aes(x = Education)) +
geom_histogram()
hist(my_vector)
hist(log(my_vector))
hist(sqrt(my_vector))
hist(1/(my_vector))
hist(sqrt(my_vector))
hist(log(my_vector))
shapiro.test(my_vector)
shapiro.test(log(my_vector))
shapiro.test(sqrt(my_vector))
shapiro.test(1/(my_vector))
#
# можно оценивать нормальность по Q-Q plot
qqnorm(my_vector, pch = 1, frame = FALSE)
qqline(my_vector, col = "steelblue", lwd = 2)
ggplot() + aes(my_vector)+ geom_histogram(binwidth=0.05, colour="black", fill="white")
ggplot() + aes(my_vector) + geom_histogram(binwidth=0.05, colour="black", fill="white")
ggplot(aes(my_vector)) +
geom_histogram(binwidth=0.05, colour="black", fill="white")
lm1 <- lm(Education ~ Examination, swiss)
summary(lm1)
swiss$Examination_squared <- (swiss$Examination)^2
lm2 <- lm(Education ~ Examination + Examination_squared, swiss)
summary(lm2)
mtcars[,c(1,3)]
mtcars <- mtcars[,c(1,3)]
x <- mtcars[,c(1,3)]
scale(x[, 1], x[,2 ])
scale(x)
x <- mtcars[,c(1,3)]
x
x <- mtcars[,c(1,3)]
mtcars[,c(1,3)]
mtcars[, c(1, 3)]
rm(mtcars)
x <- mtcars[, c(1, 3)]
scale(x[, 1], x[,2 ])
scale(x$)
scale(x$mpg)
scale(x$mpg, x$disp)
scale(c(x$mpg, x$disp))
scale(c(x$mpg)
scale(x$mpg)
scale(x$mpg)
scale(c(x$mpg, x$disp))
scale(x[, 1], x[,2 ])
scale(cbind(x$mpg, x$disp))
x <- scale(cbind(x$mpg, x$disp))
View(x)
scale(cbind(x[, 1], x[,2 ]))
lm(x[, 1] ~  x[,2 ], x)
lm(x[, 1] ~  x[, 2], x)
lm(x[, 1] ~  x[, 2], x)
x <- as.data.frame(scale(cbind(x[, 1], x[,2 ])))
View(x)
fit <- lm(x[, 1] ~  x[, 2], x)
fit
str(fit)
lm(x[, 1] ~  x[, 2], x)$coefficients
fit
fit <- lm(x[, 1] ~  x[, 2], x)$coefficients
fit
beta.coef <- function(x) {
x <- as.data.frame(scale(cbind(x[, 1], x[,2 ])))
fit <- lm(x[, 1] ~  x[, 2], x)$coefficients
return(fit)
}
beta.coef(x)
#### Step 8 of 9  ####
# То, что вы только что сделали, можно сделать с помощью функции lm.beta из библиотеки QuantPsyc! :)
install.packages(QuantPsyc)
#### Step 8 of 9  ####
# То, что вы только что сделали, можно сделать с помощью функции lm.beta из библиотеки QuantPsyc! :)
install.packages('QuantPsyc')
library(QuantPsyc)
lm.beta(lm(x[, 1] ~  x[, 2], x))
beta.coef(x)
shapiro.test(x[, 1])
shapiro.test(x[, 1], x[, 2])
shapiro.test(cbind(x[, 1], x[, 2]))
shapiro.test(cbind(x[, 1], x[, 2]))$p-value
shapiro.test(cbind(x[, 1], x[, 2]))$p.value
shapiro.test([, 1])$p.value
shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2
cbind(shapiro1, shapiro2)
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
}
normality.test(x)
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
}
remove(list = ls())
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
}
normality.test(x)
x <- mtcars[,c(1,3)]
normality.test(x)
normality.test(x)
lm.beta(lm(x[, 1] ~  x[, 2], x))
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
return(pvalue)
}
normality.test(x)
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
return(as.vector(pvalue))
}
normality.test(x)
paste(nemes(x), as.vector(pvalue))
vec <- paste(nemes(x), as.vector(pvalue))
nemes(x)
paste(names(x), as.vector(pvalue))
pvalue <- cbind(shapiro1, shapiro2)
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
vec <- paste(names(x), as.vector(pvalue))
return(as.vector(pvalue))
}
normality.test(x)
normality.test <- function(x) {
shapiro1 <- shapiro.test(x[, 1])$p.value
shapiro2 <- shapiro.test(x[, 2])$p.value
pvalue <- cbind(shapiro1, shapiro2)
vec <- paste(names(x), as.vector(pvalue))
return(as.vector(vec))
}
normality.test(x)
